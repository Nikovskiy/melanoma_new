# app.py
import streamlit as st
import torch
import torch.nn as nn
import torchvision.models as models
from torchvision.models import MobileNet_V2_Weights
from torchvision import transforms
from PIL import Image
import requests
from io import BytesIO
import time
import numpy as np

# ===========================
# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
# ===========================
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

# ===========================
# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# ===========================
@st.cache_resource
def load_model():
    num_classes = 6
    model = models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT)
    model.classifier[1] = nn.Linear(1280, num_classes)
    model.load_state_dict(torch.load("models/model.pth", map_location=device))

    
    model = model.to(device)
    model.eval()
    return model

model = load_model()
preprocess = MobileNet_V2_Weights.DEFAULT.transforms()
CLASS_NAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']

# ===========================
# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
# ===========================
def predict_image(image: Image.Image):
    start_time = time.time()
    input_tensor = preprocess(image).unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(input_tensor)
        probs = torch.softmax(output, dim=1).cpu().numpy()[0]
        pred_class = CLASS_NAMES[output.argmax().item()]
    end_time = time.time()
    inference_time = end_time - start_time
    return pred_class, probs, inference_time

# ===========================
# Streamlit UI
# ===========================
st.set_page_config(page_title="Intel Image Classification", layout="wide")
st.title("üñºÔ∏è Intel Image Classification")

# –í–∫–ª–∞–¥–∫–∏
tab1, tab2, tab3 = st.tabs(["üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã", "üîó –ü–æ —Å—Å—ã–ª–∫–µ", "üì§ –ù–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"])

# --- –í–∫–ª–∞–¥–∫–∞ 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ ---
with tab1:
    uploaded_files = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", accept_multiple_files=True, type=["jpg", "jpeg", "png"])
    if uploaded_files:
        for uploaded_file in uploaded_files:
            image = Image.open(uploaded_file).convert("RGB")
            st.image(image, caption=uploaded_file.name, width=300)
            pred, probs, t = predict_image(image)
            st.success(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:** {pred} | **–í—Ä–µ–º—è:** {t:.3f} —Å–µ–∫")
            st.bar_chart(dict(zip(CLASS_NAMES, probs)))

# --- –í–∫–ª–∞–¥–∫–∞ 2: –ü–æ —Å—Å—ã–ª–∫–µ ---
with tab2:
    url = st.text_input("–í—Å—Ç–∞–≤—å—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–¥–æ–ª–∂–µ–Ω –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è –Ω–∞ .jpg/.png)")
    if url:
        try:
            response = requests.get(url)
            image = Image.open(BytesIO(response.content)).convert("RGB")
            st.image(image, caption="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ URL", width=300)
            pred, probs, t = predict_image(image)
            st.success(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:** {pred} | **–í—Ä–µ–º—è:** {t:.3f} —Å–µ–∫")
            st.bar_chart(dict(zip(CLASS_NAMES, probs)))
        except Exception as e:
            st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")

# --- –í–∫–ª–∞–¥–∫–∞ 3: –ù–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–º–∞—Å—Å–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞) ---
with tab3:
    st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    multi_files = st.file_uploader("–ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞", accept_multiple_files=True, type=["jpg", "jpeg", "png"], key="multi")
    if multi_files:
        total_time = 0.0
        results = []
        for f in multi_files:
            image = Image.open(f).convert("RGB")
            pred, probs, t = predict_image(image)
            total_time += t
            results.append((f.name, pred, t))
        
        st.write(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(multi_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∑–∞ {total_time:.3f} —Å–µ–∫ (–≤ —Å—Ä–µ–¥–Ω–µ–º: {total_time/len(multi_files):.3f} —Å–µ–∫/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)")
        
        for name, pred, t in results:
            st.write(f"- **{name}** ‚Üí `{pred}` ({t:.3f} —Å–µ–∫)")

st.divider()
st.caption("–ú–æ–¥–µ–ª—å: MobileNetV2 (ImageNet ‚Üí fine-tuned –Ω–∞ Intel Image Classification)")